{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b217668-a351-4094-aa61-8c6300cbaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77750ed8-b186-4550-a050-354da3ac6546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset  # pip install datasets\n",
    "\n",
    "ytt = load_dataset(\n",
    "    \"pinecone/yt-transcriptions\",\n",
    "    split=\"train\",\n",
    "    revision=\"926a45\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977c592a-f61b-4083-a7c0-2c0bc9e4f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_id': 'ZPewmEu7644', 'text': \" hi this is Jeff Dean welcome to applications of deep neural networks of Washington University in this video we're going to look at how we can use ganz to generate additional training data for the latest on my a I course and projects click subscribe in the bell next to it to be notified of every new video Dan's have a wide array of uses beyond just the face generation that you\", 'start_second': 0, 'end_second': 20, 'url': 'https://www.youtube.com/watch?v=ZPewmEu7644&t=0s', 'title': 'GANS for Semi-Supervised Learning in Keras (7.4)', 'thumbnail': 'https://i.ytimg.com/vi/ZPewmEu7644/maxresdefault.jpg'}\n"
     ]
    }
   ],
   "source": [
    "for x in ytt:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583f6c49-057b-4923-a692-cc5d2515f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 06:25:17.447654: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-20 06:25:17.496286: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-20 06:25:17.497847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-20 06:25:18.334668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "retriever = SentenceTransformer(\n",
    "    'flax-sentence-embeddings/all_datasets_v3_mpnet-base'\n",
    ")\n",
    "retriever.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4bc705-fa0d-4ae8-ad1e-d7811ad05349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = retriever.get_sentence_embedding_dimension()\n",
    "embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b25a741-42a6-40a1-b5b9-1f68a692567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# get api key from app.pinecone.io\n",
    "pinecone = Pinecone(\n",
    "    api_key=\"55e1c7a7-6374-4a46-9650-b075f74e2158\",\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "\n",
    "# connect to new index\n",
    "index = pinecone.Index(\"youtube-search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8513c1-612b-4f23-8d5f-deac93766031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf349ef24f4341d38c6f853a0008b855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "docs = []  # this will store IDs, embeddings, and metadata\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(ytt), batch_size)):\n",
    "    i_end = min(i+batch_size, len(ytt))\n",
    "    # extract batch from YT transactions data\n",
    "    batch = ytt[i:i_end]\n",
    "    # encode batch of text\n",
    "    embeds = retriever.encode(batch['text']).tolist()\n",
    "    # each snippet needs a unique ID\n",
    "    # we will merge video ID and start_seconds for this\n",
    "    ids = [f\"{x[0]}-{x[1]}\" for x in zip(batch['video_id'], batch['start_second'])]\n",
    "    # create metadata records\n",
    "    meta = [{\n",
    "        'video_id': x[0],\n",
    "        'title': x[1],\n",
    "        'text': x[2],\n",
    "        'start_second': x[3],\n",
    "        'end_second': x[4],\n",
    "        'url': x[5],\n",
    "        'thumbnail': x[6]\n",
    "    } for x in zip(\n",
    "        batch['video_id'],\n",
    "        batch['title'],\n",
    "        batch['text'],\n",
    "        batch['start_second'],\n",
    "        batch['end_second'],\n",
    "        batch['url'],\n",
    "        batch['thumbnail']\n",
    "    )]\n",
    "    # create list of (IDs, vectors, metadata) to upsert\n",
    "    to_upsert = list(zip(ids, embeds, meta))\n",
    "    # add to pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1f46de-33b6-4dd7-8806-76c31f609b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Teach me transformers\"\n",
    "\n",
    "xq = retriever.encode([query]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4bb209-551c-442e-8611-0d255c09caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = index.query(vector=xq, top_k=5,\n",
    "                 include_metadata=True)\n",
    "# for context in xc['matches']:\n",
    "#     print(context['metadata']['text'], end=\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14de979f-531e-459f-92d2-5240ec2eac3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'Uumd2zOOz60-114',\n",
       "              'metadata': {'end_second': 139.0,\n",
       "                           'start_second': 114.0,\n",
       "                           'text': ' a video if made lots of videos on '\n",
       "                                   'transformers attention is all you need is '\n",
       "                                   'the base paper for that so I know what a '\n",
       "                                   'transformer is okay and I know that '\n",
       "                                   'transformers are usually in NLP are '\n",
       "                                   'usually used in NLP door there are things '\n",
       "                                   'like you know other things with '\n",
       "                                   'transformers but usually an NLP model then '\n",
       "                                   'I read object detection and I know object '\n",
       "                                   'detection is',\n",
       "                           'thumbnail': 'https://i.ytimg.com/vi/Uumd2zOOz60/maxresdefault.jpg',\n",
       "                           'title': \"How I Read a Paper: Facebook's DETR \"\n",
       "                                    '(Video Tutorial)',\n",
       "                           'url': 'https://www.youtube.com/watch?v=Uumd2zOOz60&t=114s',\n",
       "                           'video_id': 'Uumd2zOOz60'},\n",
       "              'score': 0.536164045,\n",
       "              'values': []},\n",
       "             {'id': 'hv3UO3G0Ofo-0',\n",
       "              'metadata': {'end_second': 28.0,\n",
       "                           'start_second': 0.0,\n",
       "                           'text': ' transformers are quickly coming for your '\n",
       "                                   'favorite models yesterday they replaced '\n",
       "                                   'lstms in nlp they used to be good at nlp '\n",
       "                                   'but blah we now have transformers think '\n",
       "                                   \"again today we're going to see that maybe \"\n",
       "                                   'in the near future transformers will '\n",
       "                                   'replace convolutions in image processing '\n",
       "                                   'so this paper is a step in toward towards '\n",
       "                                   'this direction you just wonder what is it '\n",
       "                                   'going to be',\n",
       "                           'thumbnail': 'https://i.ytimg.com/vi/hv3UO3G0Ofo/maxresdefault.jpg',\n",
       "                           'title': 'Axial-DeepLab: Stand-Alone '\n",
       "                                    'Axial-Attention for Panoptic Segmentation '\n",
       "                                    '(Paper Explained)',\n",
       "                           'url': 'https://www.youtube.com/watch?v=hv3UO3G0Ofo&t=0s',\n",
       "                           'video_id': 'hv3UO3G0Ofo'},\n",
       "              'score': 0.462005913,\n",
       "              'values': []},\n",
       "             {'id': 'S27pHKBEp30-1527',\n",
       "              'metadata': {'end_second': 1549.0,\n",
       "                           'start_second': 1527.0,\n",
       "                           'text': ' before Bert and transformers and the '\n",
       "                                   'Muppets this just was not possible now you '\n",
       "                                   \"can leverage other people's work in this \"\n",
       "                                   \"way and I think that's really amazing so \"\n",
       "                                   'to sum up the key advantages of these '\n",
       "                                   \"transforming networks yes they're easier \"\n",
       "                                   \"to train they're more efficient all that \"\n",
       "                                   'yada yada yada but more importantly '\n",
       "                                   'transfer learning actually works with them '\n",
       "                                   'right you can',\n",
       "                           'thumbnail': 'https://i.ytimg.com/vi/S27pHKBEp30/maxresdefault.jpg',\n",
       "                           'title': 'LSTM is dead. Long Live Transformers!',\n",
       "                           'url': 'https://www.youtube.com/watch?v=S27pHKBEp30&t=1527s',\n",
       "                           'video_id': 'S27pHKBEp30'},\n",
       "              'score': 0.46037963,\n",
       "              'values': []},\n",
       "             {'id': 'nv6oFDp6rNQ-3678',\n",
       "              'metadata': {'end_second': 3703.0,\n",
       "                           'start_second': 3678.0,\n",
       "                           'text': ' training might not be done here first of '\n",
       "                                   'all and second of all it would be really '\n",
       "                                   'interesting to see how this works out with '\n",
       "                                   'you know sizes of transformers and like '\n",
       "                                   'especially these these huge transformers '\n",
       "                                   'just the fact that they can keep learning '\n",
       "                                   'the more we train them might be you know '\n",
       "                                   'be interpreted in the light of what kind '\n",
       "                                   'of states they converge to and the fact '\n",
       "                                   'that there are tension',\n",
       "                           'thumbnail': 'https://i.ytimg.com/vi/nv6oFDp6rNQ/maxresdefault.jpg',\n",
       "                           'title': 'Hopfield Networks is All You Need (Paper '\n",
       "                                    'Explained)',\n",
       "                           'url': 'https://www.youtube.com/watch?v=nv6oFDp6rNQ&t=3678s',\n",
       "                           'video_id': 'nv6oFDp6rNQ'},\n",
       "              'score': 0.454066038,\n",
       "              'values': []},\n",
       "             {'id': 'T35ba_VXkMY-1047',\n",
       "              'metadata': {'end_second': 1077.0,\n",
       "                           'start_second': 1047.0,\n",
       "                           'text': ' into an equally long sequence yet again '\n",
       "                                   'of features and the good thing about a '\n",
       "                                   'transformer because why do you use a '\n",
       "                                   'transformer the good thing about the '\n",
       "                                   'transformer is that in such a sequence and '\n",
       "                                   \"I've done videos on transformers it you \"\n",
       "                                   'can basic mainly look at the video '\n",
       "                                   'attention is all you need if you want to '\n",
       "                                   'under than this more fully this thing can '\n",
       "                                   'basically have a tension so it has',\n",
       "                           'thumbnail': 'https://i.ytimg.com/vi/T35ba_VXkMY/maxresdefault.jpg',\n",
       "                           'title': 'DETR: End-to-End Object Detection with '\n",
       "                                    'Transformers (Paper Explained)',\n",
       "                           'url': 'https://www.youtube.com/watch?v=T35ba_VXkMY&t=1047s',\n",
       "                           'video_id': 'T35ba_VXkMY'},\n",
       "              'score': 0.446087807,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aea17b-0567-4ae8-9de0-847013d0a033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e44ee-1a63-43d0-95f9-873ab34ba6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85636701-2523-434b-a06f-70276b8f3ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
